# -*- coding: utf-8 -*-
"""Ride Share ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dY4olSj7tsUNYLidverSZlrXvqPpoqoH
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np

data = pd.read_csv("hour.csv")
data.head()

data = data.drop(columns=['instant', 'dteday', 'casual', 'registered'])
data = pd.get_dummies(data, columns=['season', 'weathersit'], drop_first=True)

data.head()

# Convert all boolean columns to int
bool_cols = data.select_dtypes(include='bool').columns
data[bool_cols] = data[bool_cols].astype(int)

data.head()

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(data.corr(), annot=True)
plt.show()

x = data.drop('cnt', axis=1)
y = data['cnt']
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

X = np.column_stack([np.ones((len(x),1)), x])
X

theta = np.linalg.solve(X.T @ X, X.T @ y)
theta

y_hat = X@theta

error = y-y_hat
sse = np.sum(error*error)
sse

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R²:", r2_score(y_test, y_pred))

residuals = y_test - y_pred
sns.histplot(residuals, kde=True)

sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')

from sklearn.tree import DecisionTreeRegressor, plot_tree
import matplotlib.pyplot as plt

# Create and fit the model
reg_tree = DecisionTreeRegressor(
    criterion='squared_error',  # for regression
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10
)
reg_tree.fit(X_train, y_train)

# Plot the tree
plt.figure(figsize=(16, 10))
plot_tree(
    reg_tree,
    feature_names=X_train.columns,
    filled=True,
    rounded=True
)
plt.title("Decision Tree Regressor")
plt.show()



y_pred_tree = reg_tree.predict(X_test)

# Evaluate the model
mae_tree = mean_absolute_error(y_test, y_pred_tree)
mse_tree = mean_squared_error(y_test, y_pred_tree)
rmse_tree = np.sqrt(mse_tree)
r2_tree = r2_score(y_test, y_pred_tree)

# Print the results
print(f"Decision Tree Regressor Performance:")
print(f"MAE : {mae_tree:.2f}")
print(f"RMSE: {rmse_tree:.2f}")
print(f"R²  : {r2_tree:.4f}")

from sklearn.ensemble import RandomForestRegressor

# Step 1: Create the model
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42
)

rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)
print(f"Random Forest Performance:")
print(f"MAE : {mae_rf:.2f}")
print(f"RMSE: {rmse_rf:.2f}")
print(f"R²  : {r2_rf:.4f}")

import joblib
joblib.dump(rf_model, "random_forest_bike_model.pkl")

X_test